{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZPVs78nj2giG7jSHrAJyT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vineeshavilla/vineesha_DataVista-Sales-Data-Analysis-and-Visualization_Infosys_Internship_Oct2024/blob/main/data_operatons_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# numpy"
      ],
      "metadata": {
        "id": "qIUkdEkGXMGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#linear regressioin\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "X_b = np.c_[np.ones((len(X), 1)), X]\n",
        "\n",
        "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
        "\n",
        "X_new = np.array([[0], [2], [3]])\n",
        "X_new_b = np.c_[np.ones((len(X_new), 1)), X_new]\n",
        "y_predict = X_new_b.dot(theta_best)\n",
        "\n",
        "print(\"Predictions:\", y_predict)"
      ],
      "metadata": {
        "id": "1L0hsUajVAR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b6ba026-92ac-4982-fb01-874fee5f3283"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [2.83106871e-15 2.00000000e+00 3.00000000e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def gradient_descent(X, y, learning_rate, iterations):\n",
        "    m = len(y)\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "    theta = np.random.randn(X_b.shape[1], 1)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        z = X_b.dot(theta)\n",
        "        predictions = sigmoid(z)\n",
        "        gradients = X_b.T.dot(predictions - y) / m\n",
        "        theta -= learning_rate * gradients\n",
        "\n",
        "    return theta\n",
        "\n",
        "X = np.array([[1], [2], [3], [4]])\n",
        "y = np.array([[0], [0], [1], [1]])\n",
        "\n",
        "theta_best = gradient_descent(X, y, learning_rate=0.1, iterations=1000)\n",
        "print(\"Best parameters:\", theta_best)\n",
        "\n",
        "X_new = np.array([[1], [3]])\n",
        "X_new_b = np.c_[np.ones((len(X_new), 1)), X_new]\n",
        "predictions = sigmoid(X_new_b.dot(theta_best))\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL2N6jspXR-E",
        "outputId": "eb56d9b5-50ef-40f5-c294-bca824e460ee"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: [[-5.62451557]\n",
            " [ 2.35872078]]\n",
            "Predictions: [[0.03676345]\n",
            " [0.81025174]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#knn(k nearest neighbors)\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Distance function\n",
        "def euclidean_distance(a, b):\n",
        "    return np.sqrt(np.sum((a - b)**2))\n",
        "\n",
        "# K-NN classifier\n",
        "def knn(X_train, y_train, X_test, k=3):\n",
        "    y_pred = []\n",
        "    for test_point in X_test:\n",
        "        distances = [euclidean_distance(test_point, x) for x in X_train]\n",
        "        k_indices = np.argsort(distances)[:k]\n",
        "        k_nearest_labels = [y_train[i] for i in k_indices]\n",
        "        majority_vote = Counter(k_nearest_labels).most_common(1)[0][0]\n",
        "        y_pred.append(majority_vote)\n",
        "    return y_pred\n",
        "\n",
        "# Sample data\n",
        "X_train = np.array([[1, 1], [2, 2], [3, 3], [6, 6], [7, 7]])\n",
        "y_train = np.array([0, 0, 0, 1, 1])\n",
        "X_test = np.array([[4, 4], [5, 5]])\n",
        "\n",
        "# Run K-NN classifier\n",
        "y_pred = knn(X_train, y_train, X_test, k=3)\n",
        "print(\"Predicted labels:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAa_vsq9ZlRp",
        "outputId": "fa6ae1c2-87f5-47f1-d174-a2d78896b1ee"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels: [0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#principal component analysis\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (each row is a data point)\n",
        "X = np.array([[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2], [3.1, 3.0]])\n",
        "\n",
        "# Standardize data (zero mean and unit variance)\n",
        "X_meaned = X - np.mean(X, axis=0)\n",
        "\n",
        "# Covariance matrix\n",
        "cov_matrix = np.cov(X_meaned.T)\n",
        "\n",
        "# Eigenvalues and eigenvectors\n",
        "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "\n",
        "# Sort eigenvectors by eigenvalues in decreasing order\n",
        "idx = eigenvalues.argsort()[::-1]\n",
        "eigenvectors = eigenvectors[:, idx]\n",
        "\n",
        "# Transform the data to the new basis\n",
        "X_pca = X_meaned.dot(eigenvectors)\n",
        "\n",
        "print(\"PCA transformed data:\\n\", X_pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGY4v6dLcvG9",
        "outputId": "fc788bd4-a029-4642-dceb-9d6f154623e0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA transformed data:\n",
            " [[ 0.44362444 -0.20099093]\n",
            " [-2.17719404 -0.05500992]\n",
            " [ 0.57071239  0.36808609]\n",
            " [-0.12902465  0.06747325]\n",
            " [ 1.29188186 -0.17955849]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kmeans clustering\n",
        "import numpy as np\n",
        "\n",
        "# Euclidean distance\n",
        "def euclidean_distance(a, b):\n",
        "    return np.sqrt(np.sum((a - b)**2))\n",
        "\n",
        "# K-Means algorithm\n",
        "def kmeans(X, k, iterations):\n",
        "    # Randomly initialize centroids\n",
        "    centroids = X[np.random.choice(X.shape[0], k, replace=False)]\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        # Assign points to the nearest centroid\n",
        "        clusters = [[] for _ in range(k)]\n",
        "        for point in X:\n",
        "            distances = [euclidean_distance(point, centroid) for centroid in centroids]\n",
        "            cluster_index = np.argmin(distances)\n",
        "            clusters[cluster_index].append(point)\n",
        "\n",
        "        # Update centroids\n",
        "        new_centroids = np.array([np.mean(cluster, axis=0) for cluster in clusters])\n",
        "        if np.all(centroids == new_centroids):\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return centroids, clusters\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])\n",
        "\n",
        "# Run K-Means\n",
        "centroids, clusters = kmeans(X, k=2, iterations=100)\n",
        "print(\"Centroids:\\n\", centroids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7zmuu5OezJx",
        "outputId": "c0ceda6f-d23a-4e29-8b42-c426205e8d86"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centroids:\n",
            " [[7.33333333 9.        ]\n",
            " [1.16666667 1.46666667]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#naive bayes\n",
        "import numpy as np\n",
        "\n",
        "# Calculate probabilities\n",
        "def calculate_probabilities(X, y):\n",
        "    unique_classes = np.unique(y)\n",
        "    probabilities = {}\n",
        "\n",
        "    for label in unique_classes:\n",
        "        X_class = X[y == label]\n",
        "        probabilities[label] = {}\n",
        "        probabilities[label]['prior'] = len(X_class) / len(y)\n",
        "        probabilities[label]['mean'] = np.mean(X_class, axis=0)\n",
        "        probabilities[label]['var'] = np.var(X_class, axis=0)\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "# Gaussian probability\n",
        "def gaussian_probability(x, mean, var):\n",
        "    coeff = 1 / np.sqrt(2 * np.pi * var)\n",
        "    exponent = np.exp(-(x - mean)**2 / (2 * var))\n",
        "    return coeff * exponent\n",
        "\n",
        "# Predict class label\n",
        "def predict(X_test, probabilities):\n",
        "    predictions = []\n",
        "    for x in X_test:\n",
        "        posteriors = {}\n",
        "        for label, params in probabilities.items():\n",
        "            prior = np.log(params['prior'])\n",
        "            likelihood = np.sum(np.log(gaussian_probability(x, params['mean'], params['var'])))\n",
        "            posteriors[label] = prior + likelihood\n",
        "        predictions.append(max(posteriors, key=posteriors.get))\n",
        "    return predictions\n",
        "\n",
        "# Sample data\n",
        "X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
        "y_train = np.array([0, 0, 1, 1, 1])\n",
        "X_test = np.array([[2.5, 3.5], [3.5, 4.5]])\n",
        "\n",
        "# Run Naive Bayes classifier\n",
        "probabilities = calculate_probabilities(X_train, y_train)\n",
        "y_pred = predict(X_test, probabilities)\n",
        "print(\"Predictions:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5dTfKF2e53o",
        "outputId": "0f70a167-e998-49a6-9f2a-4185841e8d88"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#svm\n",
        "import numpy as np\n",
        "\n",
        "# Hinge loss function for SVM\n",
        "def hinge_loss(X, y, w, b, reg_strength):\n",
        "    n_samples = X.shape[0]\n",
        "    distances = 1 - y * (np.dot(X, w) + b)\n",
        "    losses = np.maximum(0, distances)\n",
        "    return reg_strength * (np.sum(losses) / n_samples)\n",
        "\n",
        "# Gradient descent for SVM\n",
        "def gradient_descent(X, y, w, b, learning_rate, iterations, reg_strength):\n",
        "    for _ in range(iterations):\n",
        "        for i, x_i in enumerate(X):\n",
        "            condition = y[i] * (np.dot(X[i], w) + b) >= 1\n",
        "            if condition:\n",
        "                w -= learning_rate * (2 * reg_strength * w)\n",
        "            else:\n",
        "                w -= learning_rate * (2 * reg_strength * w - np.dot(X[i], y[i]))\n",
        "                b -= learning_rate * y[i]\n",
        "    return w, b\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1, 2], [2, 3], [3, 3], [4, 5], [5, 6]])\n",
        "y = np.array([1, 1, -1, -1, -1])\n",
        "\n",
        "# Parameters\n",
        "w = np.zeros(X.shape[1])\n",
        "b = 0\n",
        "learning_rate = 0.001\n",
        "iterations = 1000\n",
        "reg_strength = 0.01\n",
        "\n",
        "# Train SVM\n",
        "w, b = gradient_descent(X, y, w, b, learning_rate, iterations, reg_strength)\n",
        "print(\"Weight vector:\", w)\n",
        "print(\"Bias term:\", b)"
      ],
      "metadata": {
        "id": "menW2WrAfDq6",
        "outputId": "a58100d1-fdb4-45c4-e808-4e7d3d34a9b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight vector: [-0.72999255  0.57392065]\n",
            "Bias term: -0.9520000000000007\n"
          ]
        }
      ]
    }
  ]
}